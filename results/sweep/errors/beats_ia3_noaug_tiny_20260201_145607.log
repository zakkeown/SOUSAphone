Seed set to 42
[2026-02-01 14:56:10,587][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-01 14:56:10,619][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/microsoft/wavlm-base-plus/4c66d4806a428f2e922ccfa1a962776e232d487b/config.json "HTTP/1.1 200 OK"
[2026-02-01 14:56:10,689][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-01 14:56:10,719][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/microsoft/wavlm-base-plus/4c66d4806a428f2e922ccfa1a962776e232d487b/config.json "HTTP/1.1 200 OK"
You are using a model of type wavlm to instantiate a model of type wav2vec2. This is not supported for all configurations of models and can yield errors.
[2026-02-01 14:56:10,797][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/model.safetensors "HTTP/1.1 404 Not Found"
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
[2026-02-01 14:56:10,797][huggingface_hub.utils._http][WARNING] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
[2026-02-01 14:56:10,873][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/model.safetensors.index.json "HTTP/1.1 404 Not Found"
[2026-02-01 14:56:10,951][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/pytorch_model.bin "HTTP/1.1 302 Found"
[2026-02-01 14:56:11,026][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/model.safetensors "HTTP/1.1 404 Not Found"

Loading weights:   0%|          | 0/211 [00:00<?, ?it/s]
Loading weights:   0%|          | 1/211 [00:00<00:00, 5857.97it/s, Materializing param=encoder.layer_norm.bias]
Loading weights:   0%|          | 1/211 [00:00<00:00, 4588.95it/s, Materializing param=encoder.layer_norm.bias]
Loading weights:   1%|          | 2/211 [00:00<00:00, 3795.75it/s, Materializing param=encoder.layer_norm.weight]
Loading weights:   1%|          | 2/211 [00:00<00:00, 3617.34it/s, Materializing param=encoder.layer_norm.weight]
Loading weights:   1%|▏         | 3/211 [00:00<00:00, 4762.65it/s, Materializing param=encoder.layers.0.attention.k_proj.bias]
Loading weights:   1%|▏         | 3/211 [00:00<00:00, 4477.90it/s, Materializing param=encoder.layers.0.attention.k_proj.bias]
Loading weights:   2%|▏         | 4/211 [00:00<00:00, 5348.17it/s, Materializing param=encoder.layers.0.attention.k_proj.weight]
Loading weights:   2%|▏         | 4/211 [00:00<00:00, 5064.06it/s, Materializing param=encoder.layers.0.attention.k_proj.weight]
Loading weights:   2%|▏         | 5/211 [00:00<00:00, 5897.50it/s, Materializing param=encoder.layers.0.attention.out_proj.bias]
Loading weights:   2%|▏         | 5/211 [00:00<00:00, 5726.79it/s, Materializing param=encoder.layers.0.attention.out_proj.bias]
Loading weights:   3%|▎         | 6/211 [00:00<00:00, 6472.69it/s, Materializing param=encoder.layers.0.attention.out_proj.weight]
Loading weights:   3%|▎         | 6/211 [00:00<00:00, 6316.72it/s, Materializing param=encoder.layers.0.attention.out_proj.weight]
Loading weights:   3%|▎         | 7/211 [00:00<00:00, 6993.84it/s, Materializing param=encoder.layers.0.attention.q_proj.bias]    
Loading weights:   3%|▎         | 7/211 [00:00<00:00, 6842.26it/s, Materializing param=encoder.layers.0.attention.q_proj.bias]
Loading weights:   4%|▍         | 8/211 [00:00<00:00, 7463.17it/s, Materializing param=encoder.layers.0.attention.q_proj.weight]
Loading weights:   4%|▍         | 8/211 [00:00<00:00, 7313.52it/s, Materializing param=encoder.layers.0.attention.q_proj.weight]
Loading weights:   4%|▍         | 9/211 [00:00<00:00, 7812.24it/s, Materializing param=encoder.layers.0.attention.v_proj.bias]  
Loading weights:   4%|▍         | 9/211 [00:00<00:00, 7678.75it/s, Materializing param=encoder.layers.0.attention.v_proj.bias]
Loading weights:   5%|▍         | 10/211 [00:00<00:00, 8177.63it/s, Materializing param=encoder.layers.0.attention.v_proj.weight]
Loading weights:   5%|▍         | 10/211 [00:00<00:00, 8031.99it/s, Materializing param=encoder.layers.0.attention.v_proj.weight]
Loading weights:   5%|▌         | 11/211 [00:00<00:00, 8501.45it/s, Materializing param=encoder.layers.0.feed_forward.intermediate_dense.bias]
Loading weights:   5%|▌         | 11/211 [00:00<00:00, 8316.03it/s, Materializing param=encoder.layers.0.feed_forward.intermediate_dense.bias]
Loading weights:   6%|▌         | 12/211 [00:00<00:00, 8634.70it/s, Materializing param=encoder.layers.0.feed_forward.intermediate_dense.weight]
Loading weights:   6%|▌         | 12/211 [00:00<00:00, 8499.10it/s, Materializing param=encoder.layers.0.feed_forward.intermediate_dense.weight]
Loading weights:   6%|▌         | 13/211 [00:00<00:00, 8910.93it/s, Materializing param=encoder.layers.0.feed_forward.output_dense.bias]        
Loading weights:   6%|▌         | 13/211 [00:00<00:00, 8749.35it/s, Materializing param=encoder.layers.0.feed_forward.output_dense.bias]
Loading weights:   7%|▋         | 14/211 [00:00<00:00, 9145.03it/s, Materializing param=encoder.layers.0.feed_forward.output_dense.weight]
Loading weights:   7%|▋         | 14/211 [00:00<00:00, 9021.39it/s, Materializing param=encoder.layers.0.feed_forward.output_dense.weight]
Loading weights:   7%|▋         | 15/211 [00:00<00:00, 9370.65it/s, Materializing param=encoder.layers.0.final_layer_norm.bias]           
Loading weights:   7%|▋         | 15/211 [00:00<00:00, 9249.42it/s, Materializing param=encoder.layers.0.final_layer_norm.bias]
Loading weights:   8%|▊         | 16/211 [00:00<00:00, 9592.46it/s, Materializing param=encoder.layers.0.final_layer_norm.weight]
Loading weights:   8%|▊         | 16/211 [00:00<00:00, 9479.99it/s, Materializing param=encoder.layers.0.final_layer_norm.weight]
Loading weights:   8%|▊         | 17/211 [00:00<00:00, 9833.56it/s, Materializing param=encoder.layers.0.layer_norm.bias]        
Loading weights:   8%|▊         | 17/211 [00:00<00:00, 9715.65it/s, Materializing param=encoder.layers.0.layer_norm.bias]
Loading weights:   9%|▊         | 18/211 [00:00<00:00, 10050.25it/s, Materializing param=encoder.layers.0.layer_norm.weight]
Loading weights:   9%|▊         | 18/211 [00:00<00:00, 9939.11it/s, Materializing param=encoder.layers.0.layer_norm.weight] 
Loading weights:   9%|▉         | 19/211 [00:00<00:00, 10265.59it/s, Materializing param=encoder.layers.1.attention.k_proj.bias]
Loading weights:   9%|▉         | 19/211 [00:00<00:00, 10144.07it/s, Materializing param=encoder.layers.1.attention.k_proj.bias]
Loading weights:   9%|▉         | 20/211 [00:00<00:00, 10427.11it/s, Materializing param=encoder.layers.1.attention.k_proj.weight]
Loading weights:   9%|▉         | 20/211 [00:00<00:00, 10325.71it/s, Materializing param=encoder.layers.1.attention.k_proj.weight]
Loading weights:  10%|▉         | 21/211 [00:00<00:00, 10600.60it/s, Materializing param=encoder.layers.1.attention.out_proj.bias]
Loading weights:  10%|▉         | 21/211 [00:00<00:00, 10473.29it/s, Materializing param=encoder.layers.1.attention.out_proj.bias]
Loading weights:  10%|█         | 22/211 [00:00<00:00, 10763.41it/s, Materializing param=encoder.layers.1.attention.out_proj.weight]
Loading weights:  10%|█         | 22/211 [00:00<00:00, 10654.05it/s, Materializing param=encoder.layers.1.attention.out_proj.weight]
Loading weights:  11%|█         | 23/211 [00:00<00:00, 10921.43it/s, Materializing param=encoder.layers.1.attention.q_proj.bias]    
Loading weights:  11%|█         | 23/211 [00:00<00:00, 10824.62it/s, Materializing param=encoder.layers.1.attention.q_proj.bias]
Loading weights:  11%|█▏        | 24/211 [00:00<00:00, 11081.38it/s, Materializing param=encoder.layers.1.attention.q_proj.weight]
Loading weights:  11%|█▏        | 24/211 [00:00<00:00, 10978.66it/s, Materializing param=encoder.layers.1.attention.q_proj.weight]
Loading weights:  12%|█▏        | 25/211 [00:00<00:00, 11190.78it/s, Materializing param=encoder.layers.1.attention.v_proj.bias]  
Loading weights:  12%|█▏        | 25/211 [00:00<00:00, 11071.44it/s, Materializing param=encoder.layers.1.attention.v_proj.bias]
Loading weights:  12%|█▏        | 26/211 [00:00<00:00, 11241.31it/s, Materializing param=encoder.layers.1.attention.v_proj.weight]
Loading weights:  12%|█▏        | 26/211 [00:00<00:00, 11144.80it/s, Materializing param=encoder.layers.1.attention.v_proj.weight]
Loading weights:  13%|█▎        | 27/211 [00:00<00:00, 11288.50it/s, Materializing param=encoder.layers.1.feed_forward.intermediate_dense.bias]
Loading weights:  13%|█▎        | 27/211 [00:00<00:00, 11185.92it/s, Materializing param=encoder.layers.1.feed_forward.intermediate_dense.bias]
Loading weights:  13%|█▎        | 28/211 [00:00<00:00, 11240.48it/s, Materializing param=encoder.layers.1.feed_forward.intermediate_dense.weight]
Loading weights:  13%|█▎        | 28/211 [00:00<00:00, 11146.59it/s, Materializing param=encoder.layers.1.feed_forward.intermediate_dense.weight]
Loading weights:  14%|█▎        | 29/211 [00:00<00:00, 11341.24it/s, Materializing param=encoder.layers.1.feed_forward.output_dense.bias]        
Loading weights:  14%|█▎        | 29/211 [00:00<00:00, 11254.15it/s, Materializing param=encoder.layers.1.feed_forward.output_dense.bias]
Loading weights:  14%|█▍        | 30/211 [00:00<00:00, 11480.76it/s, Materializing param=encoder.layers.1.feed_forward.output_dense.weight]
Loading weights:  14%|█▍        | 30/211 [00:00<00:00, 11389.31it/s, Materializing param=encoder.layers.1.feed_forward.output_dense.weight]
Loading weights:  15%|█▍        | 31/211 [00:00<00:00, 11619.61it/s, Materializing param=encoder.layers.1.final_layer_norm.bias]           
Loading weights:  15%|█▍        | 31/211 [00:00<00:00, 11537.13it/s, Materializing param=encoder.layers.1.final_layer_norm.bias]
Loading weights:  15%|█▌        | 32/211 [00:00<00:00, 11765.23it/s, Materializing param=encoder.layers.1.final_layer_norm.weight]
Loading weights:  15%|█▌        | 32/211 [00:00<00:00, 11683.30it/s, Materializing param=encoder.layers.1.final_layer_norm.weight]
Loading weights:  16%|█▌        | 33/211 [00:00<00:00, 11900.27it/s, Materializing param=encoder.layers.1.layer_norm.bias]        
Loading weights:  16%|█▌        | 33/211 [00:00<00:00, 11824.02it/s, Materializing param=encoder.layers.1.layer_norm.bias]
Loading weights:  16%|█▌        | 34/211 [00:00<00:00, 12044.45it/s, Materializing param=encoder.layers.1.layer_norm.weight]
Loading weights:  16%|█▌        | 34/211 [00:00<00:00, 11968.64it/s, Materializing param=encoder.layers.1.layer_norm.weight]
Loading weights:  17%|█▋        | 35/211 [00:00<00:00, 12123.27it/s, Materializing param=encoder.layers.2.attention.k_proj.bias]
Loading weights:  17%|█▋        | 35/211 [00:00<00:00, 12040.73it/s, Materializing param=encoder.layers.2.attention.k_proj.bias]
Loading weights:  17%|█▋        | 36/211 [00:00<00:00, 12117.40it/s, Materializing param=encoder.layers.2.attention.k_proj.weight]
Loading weights:  17%|█▋        | 36/211 [00:00<00:00, 12041.06it/s, Materializing param=encoder.layers.2.attention.k_proj.weight]
Loading weights:  18%|█▊        | 37/211 [00:00<00:00, 12208.09it/s, Materializing param=encoder.layers.2.attention.out_proj.bias]
Loading weights:  18%|█▊        | 37/211 [00:00<00:00, 12127.95it/s, Materializing param=encoder.layers.2.attention.out_proj.bias]
Loading weights:  18%|█▊        | 38/211 [00:00<00:00, 12285.79it/s, Materializing param=encoder.layers.2.attention.out_proj.weight]
Loading weights:  18%|█▊        | 38/211 [00:00<00:00, 12203.01it/s, Materializing param=encoder.layers.2.attention.out_proj.weight]
Loading weights:  18%|█▊        | 39/211 [00:00<00:00, 12334.33it/s, Materializing param=encoder.layers.2.attention.q_proj.bias]    
Loading weights:  18%|█▊        | 39/211 [00:00<00:00, 12256.70it/s, Materializing param=encoder.layers.2.attention.q_proj.bias]
Loading weights:  19%|█▉        | 40/211 [00:00<00:00, 12391.77it/s, Materializing param=encoder.layers.2.attention.q_proj.weight]
Loading weights:  19%|█▉        | 40/211 [00:00<00:00, 12315.36it/s, Materializing param=encoder.layers.2.attention.q_proj.weight]
Loading weights:  19%|█▉        | 41/211 [00:00<00:00, 12432.51it/s, Materializing param=encoder.layers.2.attention.v_proj.bias]  
Loading weights:  19%|█▉        | 41/211 [00:00<00:00, 12360.13it/s, Materializing param=encoder.layers.2.attention.v_proj.bias]
Loading weights:  20%|█▉        | 42/211 [00:00<00:00, 12503.43it/s, Materializing param=encoder.layers.2.attention.v_proj.weight]
Loading weights:  20%|█▉        | 42/211 [00:00<00:00, 12425.81it/s, Materializing param=encoder.layers.2.attention.v_proj.weight]
Loading weights:  20%|██        | 43/211 [00:00<00:00, 12573.55it/s, Materializing param=encoder.layers.2.feed_forward.intermediate_dense.bias]
Loading weights:  20%|██        | 43/211 [00:00<00:00, 12500.35it/s, Materializing param=encoder.layers.2.feed_forward.intermediate_dense.bias]
Loading weights:  21%|██        | 44/211 [00:00<00:00, 12600.67it/s, Materializing param=encoder.layers.2.feed_forward.intermediate_dense.weight]
Loading weights:  21%|██        | 44/211 [00:00<00:00, 12528.81it/s, Materializing param=encoder.layers.2.feed_forward.intermediate_dense.weight]
Loading weights:  21%|██▏       | 45/211 [00:00<00:00, 12669.91it/s, Materializing param=encoder.layers.2.feed_forward.output_dense.bias]        
Loading weights:  21%|██▏       | 45/211 [00:00<00:00, 12594.67it/s, Materializing param=encoder.layers.2.feed_forward.output_dense.bias]
Loading weights:  22%|██▏       | 46/211 [00:00<00:00, 12676.61it/s, Materializing param=encoder.layers.2.feed_forward.output_dense.weight]
Loading weights:  22%|██▏       | 46/211 [00:00<00:00, 12607.03it/s, Materializing param=encoder.layers.2.feed_forward.output_dense.weight]
Loading weights:  22%|██▏       | 47/211 [00:00<00:00, 12744.52it/s, Materializing param=encoder.layers.2.final_layer_norm.bias]           
Loading weights:  22%|██▏       | 47/211 [00:00<00:00, 12672.43it/s, Materializing param=encoder.layers.2.final_layer_norm.bias]
Loading weights:  23%|██▎       | 48/211 [00:00<00:00, 12803.78it/s, Materializing param=encoder.layers.2.final_layer_norm.weight]
Loading weights:  23%|██▎       | 48/211 [00:00<00:00, 12735.74it/s, Materializing param=encoder.layers.2.final_layer_norm.weight]
Loading weights:  23%|██▎       | 49/211 [00:00<00:00, 12868.38it/s, Materializing param=encoder.layers.2.layer_norm.bias]        
Loading weights:  23%|██▎       | 49/211 [00:00<00:00, 12797.07it/s, Materializing param=encoder.layers.2.layer_norm.bias]
Loading weights:  24%|██▎       | 50/211 [00:00<00:00, 12930.22it/s, Materializing param=encoder.layers.2.layer_norm.weight]
Loading weights:  24%|██▎       | 50/211 [00:00<00:00, 12863.60it/s, Materializing param=encoder.layers.2.layer_norm.weight]
Loading weights:  24%|██▍       | 51/211 [00:00<00:00, 12990.98it/s, Materializing param=encoder.layers.3.attention.k_proj.bias]
Loading weights:  24%|██▍       | 51/211 [00:00<00:00, 12921.92it/s, Materializing param=encoder.layers.3.attention.k_proj.bias]
Loading weights:  25%|██▍       | 52/211 [00:00<00:00, 13049.17it/s, Materializing param=encoder.layers.3.attention.k_proj.weight]
Loading weights:  25%|██▍       | 52/211 [00:00<00:00, 12983.92it/s, Materializing param=encoder.layers.3.attention.k_proj.weight]
Loading weights:  25%|██▌       | 53/211 [00:00<00:00, 13109.52it/s, Materializing param=encoder.layers.3.attention.out_proj.bias]
Loading weights:  25%|██▌       | 53/211 [00:00<00:00, 13041.84it/s, Materializing param=encoder.layers.3.attention.out_proj.bias]
Loading weights:  26%|██▌       | 54/211 [00:00<00:00, 13154.40it/s, Materializing param=encoder.layers.3.attention.out_proj.weight]
Loading weights:  26%|██▌       | 54/211 [00:00<00:00, 13087.51it/s, Materializing param=encoder.layers.3.attention.out_proj.weight]
Loading weights:  26%|██▌       | 55/211 [00:00<00:00, 13212.30it/s, Materializing param=encoder.layers.3.attention.q_proj.bias]    
Loading weights:  26%|██▌       | 55/211 [00:00<00:00, 13152.04it/s, Materializing param=encoder.layers.3.attention.q_proj.bias]
Loading weights:  27%|██▋       | 56/211 [00:00<00:00, 13273.86it/s, Materializing param=encoder.layers.3.attention.q_proj.weight]
Loading weights:  27%|██▋       | 56/211 [00:00<00:00, 13208.18it/s, Materializing param=encoder.layers.3.attention.q_proj.weight]
Loading weights:  27%|██▋       | 57/211 [00:00<00:00, 13333.07it/s, Materializing param=encoder.layers.3.attention.v_proj.bias]  
Loading weights:  27%|██▋       | 57/211 [00:00<00:00, 13274.59it/s, Materializing param=encoder.layers.3.attention.v_proj.bias]
Loading weights:  27%|██▋       | 58/211 [00:00<00:00, 13386.32it/s, Materializing param=encoder.layers.3.attention.v_proj.weight]
Loading weights:  27%|██▋       | 58/211 [00:00<00:00, 13330.57it/s, Materializing param=encoder.layers.3.attention.v_proj.weight]
Loading weights:  28%|██▊       | 59/211 [00:00<00:00, 13382.22it/s, Materializing param=encoder.layers.3.feed_forward.intermediate_dense.bias]
Loading weights:  28%|██▊       | 59/211 [00:00<00:00, 13324.57it/s, Materializing param=encoder.layers.3.feed_forward.intermediate_dense.bias]
Loading weights:  28%|██▊       | 60/211 [00:00<00:00, 13417.48it/s, Materializing param=encoder.layers.3.feed_forward.intermediate_dense.weight]
Loading weights:  28%|██▊       | 60/211 [00:00<00:00, 13351.28it/s, Materializing param=encoder.layers.3.feed_forward.intermediate_dense.weight]
Loading weights:  29%|██▉       | 61/211 [00:00<00:00, 13454.59it/s, Materializing param=encoder.layers.3.feed_forward.output_dense.bias]        
Loading weights:  29%|██▉       | 61/211 [00:00<00:00, 13392.62it/s, Materializing param=encoder.layers.3.feed_forward.output_dense.bias]
Loading weights:  29%|██▉       | 62/211 [00:00<00:00, 13457.89it/s, Materializing param=encoder.layers.3.feed_forward.output_dense.weight]
Loading weights:  29%|██▉       | 62/211 [00:00<00:00, 13402.40it/s, Materializing param=encoder.layers.3.feed_forward.output_dense.weight]
Loading weights:  30%|██▉       | 63/211 [00:00<00:00, 13461.77it/s, Materializing param=encoder.layers.3.final_layer_norm.bias]           
Loading weights:  30%|██▉       | 63/211 [00:00<00:00, 13407.13it/s, Materializing param=encoder.layers.3.final_layer_norm.bias]
Loading weights:  30%|███       | 64/211 [00:00<00:00, 13468.24it/s, Materializing param=encoder.layers.3.final_layer_norm.weight]
Loading weights:  30%|███       | 64/211 [00:00<00:00, 13411.71it/s, Materializing param=encoder.layers.3.final_layer_norm.weight]
Loading weights:  31%|███       | 65/211 [00:00<00:00, 13513.25it/s, Materializing param=encoder.layers.3.layer_norm.bias]        
Loading weights:  31%|███       | 65/211 [00:00<00:00, 13454.56it/s, Materializing param=encoder.layers.3.layer_norm.bias]
Loading weights:  31%|███▏      | 66/211 [00:00<00:00, 13558.51it/s, Materializing param=encoder.layers.3.layer_norm.weight]
Loading weights:  31%|███▏      | 66/211 [00:00<00:00, 13502.95it/s, Materializing param=encoder.layers.3.layer_norm.weight]
Loading weights:  32%|███▏      | 67/211 [00:00<00:00, 13598.76it/s, Materializing param=encoder.layers.4.attention.k_proj.bias]
Loading weights:  32%|███▏      | 67/211 [00:00<00:00, 13543.71it/s, Materializing param=encoder.layers.4.attention.k_proj.bias]
Loading weights:  32%|███▏      | 68/211 [00:00<00:00, 13624.38it/s, Materializing param=encoder.layers.4.attention.k_proj.weight]
Loading weights:  32%|███▏      | 68/211 [00:00<00:00, 13569.92it/s, Materializing param=encoder.layers.4.attention.k_proj.weight]
Loading weights:  33%|███▎      | 69/211 [00:00<00:00, 13660.94it/s, Materializing param=encoder.layers.4.attention.out_proj.bias]
Loading weights:  33%|███▎      | 69/211 [00:00<00:00, 13606.99it/s, Materializing param=encoder.layers.4.attention.out_proj.bias]
Loading weights:  33%|███▎      | 70/211 [00:00<00:00, 13701.12it/s, Materializing param=encoder.layers.4.attention.out_proj.weight]
Loading weights:  33%|███▎      | 70/211 [00:00<00:00, 13650.79it/s, Materializing param=encoder.layers.4.attention.out_proj.weight]
Loading weights:  34%|███▎      | 71/211 [00:00<00:00, 13746.74it/s, Materializing param=encoder.layers.4.attention.q_proj.bias]    
Loading weights:  34%|███▎      | 71/211 [00:00<00:00, 13691.12it/s, Materializing param=encoder.layers.4.attention.q_proj.bias]
Loading weights:  34%|███▍      | 72/211 [00:00<00:00, 13782.57it/s, Materializing param=encoder.layers.4.attention.q_proj.weight]
Loading weights:  34%|███▍      | 72/211 [00:00<00:00, 13727.44it/s, Materializing param=encoder.layers.4.attention.q_proj.weight]
Loading weights:  35%|███▍      | 73/211 [00:00<00:00, 13815.73it/s, Materializing param=encoder.layers.4.attention.v_proj.bias]  
Loading weights:  35%|███▍      | 73/211 [00:00<00:00, 13763.56it/s, Materializing param=encoder.layers.4.attention.v_proj.bias]
Loading weights:  35%|███▌      | 74/211 [00:00<00:00, 13770.12it/s, Materializing param=encoder.layers.4.attention.v_proj.weight]
Loading weights:  35%|███▌      | 74/211 [00:00<00:00, 13724.45it/s, Materializing param=encoder.layers.4.attention.v_proj.weight]
Loading weights:  36%|███▌      | 75/211 [00:00<00:00, 13807.35it/s, Materializing param=encoder.layers.4.feed_forward.intermediate_dense.bias]
Loading weights:  36%|███▌      | 75/211 [00:00<00:00, 13754.22it/s, Materializing param=encoder.layers.4.feed_forward.intermediate_dense.bias]
Loading weights:  36%|███▌      | 76/211 [00:00<00:00, 13803.62it/s, Materializing param=encoder.layers.4.feed_forward.intermediate_dense.weight]
Loading weights:  36%|███▌      | 76/211 [00:00<00:00, 13753.60it/s, Materializing param=encoder.layers.4.feed_forward.intermediate_dense.weight]
Loading weights:  36%|███▋      | 77/211 [00:00<00:00, 13811.80it/s, Materializing param=encoder.layers.4.feed_forward.output_dense.bias]        
Loading weights:  36%|███▋      | 77/211 [00:00<00:00, 13765.30it/s, Materializing param=encoder.layers.4.feed_forward.output_dense.bias]
Loading weights:  37%|███▋      | 78/211 [00:00<00:00, 13839.66it/s, Materializing param=encoder.layers.4.feed_forward.output_dense.weight]
Loading weights:  37%|███▋      | 78/211 [00:00<00:00, 13786.01it/s, Materializing param=encoder.layers.4.feed_forward.output_dense.weight]
Loading weights:  37%|███▋      | 79/211 [00:00<00:00, 13869.24it/s, Materializing param=encoder.layers.4.final_layer_norm.bias]           
Loading weights:  37%|███▋      | 79/211 [00:00<00:00, 13816.61it/s, Materializing param=encoder.layers.4.final_layer_norm.bias]
Loading weights:  38%|███▊      | 80/211 [00:00<00:00, 13903.39it/s, Materializing param=encoder.layers.4.final_layer_norm.weight]
Loading weights:  38%|███▊      | 80/211 [00:00<00:00, 13850.59it/s, Materializing param=encoder.layers.4.final_layer_norm.weight]
Loading weights:  38%|███▊      | 81/211 [00:00<00:00, 13929.99it/s, Materializing param=encoder.layers.4.layer_norm.bias]        
Loading weights:  38%|███▊      | 81/211 [00:00<00:00, 13882.18it/s, Materializing param=encoder.layers.4.layer_norm.bias]
Loading weights:  39%|███▉      | 82/211 [00:00<00:00, 13964.55it/s, Materializing param=encoder.layers.4.layer_norm.weight]
Loading weights:  39%|███▉      | 82/211 [00:00<00:00, 13917.65it/s, Materializing param=encoder.layers.4.layer_norm.weight]
Loading weights:  39%|███▉      | 83/211 [00:00<00:00, 13992.25it/s, Materializing param=encoder.layers.5.attention.k_proj.bias]
Loading weights:  39%|███▉      | 83/211 [00:00<00:00, 13944.61it/s, Materializing param=encoder.layers.5.attention.k_proj.bias]
Loading weights:  40%|███▉      | 84/211 [00:00<00:00, 13993.23it/s, Materializing param=encoder.layers.5.attention.k_proj.weight]
Loading weights:  40%|███▉      | 84/211 [00:00<00:00, 13948.91it/s, Materializing param=encoder.layers.5.attention.k_proj.weight]
Loading weights:  40%|████      | 85/211 [00:00<00:00, 14024.46it/s, Materializing param=encoder.layers.5.attention.out_proj.bias]
Loading weights:  40%|████      | 85/211 [00:00<00:00, 13978.27it/s, Materializing param=encoder.layers.5.attention.out_proj.bias]
Loading weights:  41%|████      | 86/211 [00:00<00:00, 14054.55it/s, Materializing param=encoder.layers.5.attention.out_proj.weight]
Loading weights:  41%|████      | 86/211 [00:00<00:00, 14011.43it/s, Materializing param=encoder.layers.5.attention.out_proj.weight]
Loading weights:  41%|████      | 87/211 [00:00<00:00, 14048.29it/s, Materializing param=encoder.layers.5.attention.q_proj.bias]    
Loading weights:  41%|████      | 87/211 [00:00<00:00, 14003.01it/s, Materializing param=encoder.layers.5.attention.q_proj.bias]
Loading weights:  42%|████▏     | 88/211 [00:00<00:00, 14075.92it/s, Materializing param=encoder.layers.5.attention.q_proj.weight]
Loading weights:  42%|████▏     | 88/211 [00:00<00:00, 14030.44it/s, Materializing param=encoder.layers.5.attention.q_proj.weight]
Loading weights:  42%|████▏     | 89/211 [00:00<00:00, 14097.70it/s, Materializing param=encoder.layers.5.attention.v_proj.bias]  
Loading weights:  42%|████▏     | 89/211 [00:00<00:00, 14053.65it/s, Materializing param=encoder.layers.5.attention.v_proj.bias]
Loading weights:  43%|████▎     | 90/211 [00:00<00:00, 14100.08it/s, Materializing param=encoder.layers.5.attention.v_proj.weight]
Loading weights:  43%|████▎     | 90/211 [00:00<00:00, 14058.60it/s, Materializing param=encoder.layers.5.attention.v_proj.weight]
Loading weights:  43%|████▎     | 91/211 [00:00<00:00, 14130.60it/s, Materializing param=encoder.layers.5.feed_forward.intermediate_dense.bias]
Loading weights:  43%|████▎     | 91/211 [00:00<00:00, 14084.71it/s, Materializing param=encoder.layers.5.feed_forward.intermediate_dense.bias]
Loading weights:  44%|████▎     | 92/211 [00:00<00:00, 14125.85it/s, Materializing param=encoder.layers.5.feed_forward.intermediate_dense.weight]
Loading weights:  44%|████▎     | 92/211 [00:00<00:00, 14084.61it/s, Materializing param=encoder.layers.5.feed_forward.intermediate_dense.weight]
Loading weights:  44%|████▍     | 93/211 [00:00<00:00, 14153.49it/s, Materializing param=encoder.layers.5.feed_forward.output_dense.bias]        
Loading weights:  44%|████▍     | 93/211 [00:00<00:00, 14107.93it/s, Materializing param=encoder.layers.5.feed_forward.output_dense.bias]
Loading weights:  45%|████▍     | 94/211 [00:00<00:00, 14171.47it/s, Materializing param=encoder.layers.5.feed_forward.output_dense.weight]
Loading weights:  45%|████▍     | 94/211 [00:00<00:00, 14128.81it/s, Materializing param=encoder.layers.5.feed_forward.output_dense.weight]
Loading weights:  45%|████▌     | 95/211 [00:00<00:00, 14198.73it/s, Materializing param=encoder.layers.5.final_layer_norm.bias]           
Loading weights:  45%|████▌     | 95/211 [00:00<00:00, 14154.34it/s, Materializing param=encoder.layers.5.final_layer_norm.bias]
Loading weights:  45%|████▌     | 96/211 [00:00<00:00, 14222.50it/s, Materializing param=encoder.layers.5.final_layer_norm.weight]
Loading weights:  45%|████▌     | 96/211 [00:00<00:00, 14180.43it/s, Materializing param=encoder.layers.5.final_layer_norm.weight]
Loading weights:  46%|████▌     | 97/211 [00:00<00:00, 14248.35it/s, Materializing param=encoder.layers.5.layer_norm.bias]        
Loading weights:  46%|████▌     | 97/211 [00:00<00:00, 14206.56it/s, Materializing param=encoder.layers.5.layer_norm.bias]
Loading weights:  46%|████▋     | 98/211 [00:00<00:00, 14275.26it/s, Materializing param=encoder.layers.5.layer_norm.weight]
Loading weights:  46%|████▋     | 98/211 [00:00<00:00, 14238.17it/s, Materializing param=encoder.layers.5.layer_norm.weight]
Loading weights:  47%|████▋     | 99/211 [00:00<00:00, 14304.18it/s, Materializing param=encoder.layers.6.attention.k_proj.bias]
Loading weights:  47%|████▋     | 99/211 [00:00<00:00, 14263.40it/s, Materializing param=encoder.layers.6.attention.k_proj.bias]
Loading weights:  47%|████▋     | 100/211 [00:00<00:00, 14324.81it/s, Materializing param=encoder.layers.6.attention.k_proj.weight]
Loading weights:  47%|████▋     | 100/211 [00:00<00:00, 14281.89it/s, Materializing param=encoder.layers.6.attention.k_proj.weight]
Loading weights:  48%|████▊     | 101/211 [00:00<00:00, 14318.42it/s, Materializing param=encoder.layers.6.attention.out_proj.bias]
Loading weights:  48%|████▊     | 101/211 [00:00<00:00, 14280.29it/s, Materializing param=encoder.layers.6.attention.out_proj.bias]
Loading weights:  48%|████▊     | 102/211 [00:00<00:00, 14344.31it/s, Materializing param=encoder.layers.6.attention.out_proj.weight]
Loading weights:  48%|████▊     | 102/211 [00:00<00:00, 14304.02it/s, Materializing param=encoder.layers.6.attention.out_proj.weight]
Loading weights:  49%|████▉     | 103/211 [00:00<00:00, 14371.22it/s, Materializing param=encoder.layers.6.attention.q_proj.bias]    
Loading weights:  49%|████▉     | 103/211 [00:00<00:00, 14331.65it/s, Materializing param=encoder.layers.6.attention.q_proj.bias]
Loading weights:  49%|████▉     | 104/211 [00:00<00:00, 14396.77it/s, Materializing param=encoder.layers.6.attention.q_proj.weight]
Loading weights:  49%|████▉     | 104/211 [00:00<00:00, 14356.96it/s, Materializing param=encoder.layers.6.attention.q_proj.weight]
Loading weights:  50%|████▉     | 105/211 [00:00<00:00, 14417.19it/s, Materializing param=encoder.layers.6.attention.v_proj.bias]  
Loading weights:  50%|████▉     | 105/211 [00:00<00:00, 14377.65it/s, Materializing param=encoder.layers.6.attention.v_proj.bias]
Loading weights:  50%|█████     | 106/211 [00:00<00:00, 14418.09it/s, Materializing param=encoder.layers.6.attention.v_proj.weight]
Loading weights:  50%|█████     | 106/211 [00:00<00:00, 14381.25it/s, Materializing param=encoder.layers.6.attention.v_proj.weight]
Loading weights:  51%|█████     | 107/211 [00:00<00:00, 14444.03it/s, Materializing param=encoder.layers.6.feed_forward.intermediate_dense.bias]
Loading weights:  51%|█████     | 107/211 [00:00<00:00, 14403.24it/s, Materializing param=encoder.layers.6.feed_forward.intermediate_dense.bias]
Loading weights:  51%|█████     | 108/211 [00:00<00:00, 14454.35it/s, Materializing param=encoder.layers.6.feed_forward.intermediate_dense.weight]
Loading weights:  51%|█████     | 108/211 [00:00<00:00, 14419.38it/s, Materializing param=encoder.layers.6.feed_forward.intermediate_dense.weight]
Loading weights:  52%|█████▏    | 109/211 [00:00<00:00, 14475.48it/s, Materializing param=encoder.layers.6.feed_forward.output_dense.bias]        
Loading weights:  52%|█████▏    | 109/211 [00:00<00:00, 14437.08it/s, Materializing param=encoder.layers.6.feed_forward.output_dense.bias]
Loading weights:  52%|█████▏    | 110/211 [00:00<00:00, 14493.10it/s, Materializing param=encoder.layers.6.feed_forward.output_dense.weight]
Loading weights:  52%|█████▏    | 110/211 [00:00<00:00, 14454.96it/s, Materializing param=encoder.layers.6.feed_forward.output_dense.weight]
Loading weights:  53%|█████▎    | 111/211 [00:00<00:00, 14515.43it/s, Materializing param=encoder.layers.6.final_layer_norm.bias]           
Loading weights:  53%|█████▎    | 111/211 [00:00<00:00, 14481.56it/s, Materializing param=encoder.layers.6.final_layer_norm.bias]
Loading weights:  53%|█████▎    | 112/211 [00:00<00:00, 14523.03it/s, Materializing param=encoder.layers.6.final_layer_norm.weight]
Loading weights:  53%|█████▎    | 112/211 [00:00<00:00, 14487.20it/s, Materializing param=encoder.layers.6.final_layer_norm.weight]
Loading weights:  54%|█████▎    | 113/211 [00:00<00:00, 14524.73it/s, Materializing param=encoder.layers.6.layer_norm.bias]        
Loading weights:  54%|█████▎    | 113/211 [00:00<00:00, 14491.42it/s, Materializing param=encoder.layers.6.layer_norm.bias]
Loading weights:  54%|█████▍    | 114/211 [00:00<00:00, 14550.26it/s, Materializing param=encoder.layers.6.layer_norm.weight]
Loading weights:  54%|█████▍    | 114/211 [00:00<00:00, 14513.16it/s, Materializing param=encoder.layers.6.layer_norm.weight]
Loading weights:  55%|█████▍    | 115/211 [00:00<00:00, 14575.44it/s, Materializing param=encoder.layers.7.attention.k_proj.bias]
Loading weights:  55%|█████▍    | 115/211 [00:00<00:00, 14538.53it/s, Materializing param=encoder.layers.7.attention.k_proj.bias]
Loading weights:  55%|█████▍    | 116/211 [00:00<00:00, 14593.26it/s, Materializing param=encoder.layers.7.attention.k_proj.weight]
Loading weights:  55%|█████▍    | 116/211 [00:00<00:00, 14558.76it/s, Materializing param=encoder.layers.7.attention.k_proj.weight]
Loading weights:  55%|█████▌    | 117/211 [00:00<00:00, 14616.04it/s, Materializing param=encoder.layers.7.attention.out_proj.bias]
Loading weights:  55%|█████▌    | 117/211 [00:00<00:00, 14579.56it/s, Materializing param=encoder.layers.7.attention.out_proj.bias]
Loading weights:  56%|█████▌    | 118/211 [00:00<00:00, 14618.62it/s, Materializing param=encoder.layers.7.attention.out_proj.weight]
Loading weights:  56%|█████▌    | 118/211 [00:00<00:00, 14584.15it/s, Materializing param=encoder.layers.7.attention.out_proj.weight]
Loading weights:  56%|█████▋    | 119/211 [00:00<00:00, 14621.15it/s, Materializing param=encoder.layers.7.attention.q_proj.bias]    
Loading weights:  56%|█████▋    | 119/211 [00:00<00:00, 14586.96it/s, Materializing param=encoder.layers.7.attention.q_proj.bias]
Loading weights:  57%|█████▋    | 120/211 [00:00<00:00, 14635.97it/s, Materializing param=encoder.layers.7.attention.q_proj.weight]
Loading weights:  57%|█████▋    | 120/211 [00:00<00:00, 14600.31it/s, Materializing param=encoder.layers.7.attention.q_proj.weight]
Loading weights:  57%|█████▋    | 121/211 [00:00<00:00, 14651.00it/s, Materializing param=encoder.layers.7.attention.v_proj.bias]  
Loading weights:  57%|█████▋    | 121/211 [00:00<00:00, 14617.25it/s, Materializing param=encoder.layers.7.attention.v_proj.bias]
Loading weights:  58%|█████▊    | 122/211 [00:00<00:00, 14668.76it/s, Materializing param=encoder.layers.7.attention.v_proj.weight]
Loading weights:  58%|█████▊    | 122/211 [00:00<00:00, 14635.62it/s, Materializing param=encoder.layers.7.attention.v_proj.weight]
Loading weights:  58%|█████▊    | 123/211 [00:00<00:00, 14695.48it/s, Materializing param=encoder.layers.7.feed_forward.intermediate_dense.bias]
Loading weights:  58%|█████▊    | 123/211 [00:00<00:00, 14662.06it/s, Materializing param=encoder.layers.7.feed_forward.intermediate_dense.bias]
Loading weights:  59%|█████▉    | 124/211 [00:00<00:00, 14713.11it/s, Materializing param=encoder.layers.7.feed_forward.intermediate_dense.weight]
Loading weights:  59%|█████▉    | 124/211 [00:00<00:00, 14679.89it/s, Materializing param=encoder.layers.7.feed_forward.intermediate_dense.weight]
Loading weights:  59%|█████▉    | 125/211 [00:00<00:00, 14725.12it/s, Materializing param=encoder.layers.7.feed_forward.output_dense.bias]        
Loading weights:  59%|█████▉    | 125/211 [00:00<00:00, 14692.11it/s, Materializing param=encoder.layers.7.feed_forward.output_dense.bias]
Loading weights:  60%|█████▉    | 126/211 [00:00<00:00, 14738.61it/s, Materializing param=encoder.layers.7.feed_forward.output_dense.weight]
Loading weights:  60%|█████▉    | 126/211 [00:00<00:00, 14704.57it/s, Materializing param=encoder.layers.7.feed_forward.output_dense.weight]
Loading weights:  60%|██████    | 127/211 [00:00<00:00, 14762.54it/s, Materializing param=encoder.layers.7.final_layer_norm.bias]           
Loading weights:  60%|██████    | 127/211 [00:00<00:00, 14731.92it/s, Materializing param=encoder.layers.7.final_layer_norm.bias]
Loading weights:  61%|██████    | 128/211 [00:00<00:00, 14777.62it/s, Materializing param=encoder.layers.7.final_layer_norm.weight]
Loading weights:  61%|██████    | 128/211 [00:00<00:00, 14744.75it/s, Materializing param=encoder.layers.7.final_layer_norm.weight]
Loading weights:  61%|██████    | 129/211 [00:00<00:00, 14795.33it/s, Materializing param=encoder.layers.7.layer_norm.bias]        
Loading weights:  61%|██████    | 129/211 [00:00<00:00, 14765.05it/s, Materializing param=encoder.layers.7.layer_norm.bias]
Loading weights:  62%|██████▏   | 130/211 [00:00<00:00, 14818.45it/s, Materializing param=encoder.layers.7.layer_norm.weight]
Loading weights:  62%|██████▏   | 130/211 [00:00<00:00, 14784.69it/s, Materializing param=encoder.layers.7.layer_norm.weight]
Loading weights:  62%|██████▏   | 131/211 [00:00<00:00, 14839.27it/s, Materializing param=encoder.layers.8.attention.k_proj.bias]
Loading weights:  62%|██████▏   | 131/211 [00:00<00:00, 14804.09it/s, Materializing param=encoder.layers.8.attention.k_proj.bias]
Loading weights:  63%|██████▎   | 132/211 [00:00<00:00, 14855.06it/s, Materializing param=encoder.layers.8.attention.k_proj.weight]
Loading weights:  63%|██████▎   | 132/211 [00:00<00:00, 14821.26it/s, Materializing param=encoder.layers.8.attention.k_proj.weight]
Loading weights:  63%|██████▎   | 133/211 [00:00<00:00, 14872.23it/s, Materializing param=encoder.layers.8.attention.out_proj.bias]
Loading weights:  63%|██████▎   | 133/211 [00:00<00:00, 14839.00it/s, Materializing param=encoder.layers.8.attention.out_proj.bias]
Loading weights:  64%|██████▎   | 134/211 [00:00<00:00, 14887.21it/s, Materializing param=encoder.layers.8.attention.out_proj.weight]
Loading weights:  64%|██████▎   | 134/211 [00:00<00:00, 14854.16it/s, Materializing param=encoder.layers.8.attention.out_proj.weight]
Loading weights:  64%|██████▍   | 135/211 [00:00<00:00, 14904.35it/s, Materializing param=encoder.layers.8.attention.q_proj.bias]    
Loading weights:  64%|██████▍   | 135/211 [00:00<00:00, 14872.64it/s, Materializing param=encoder.layers.8.attention.q_proj.bias]
Loading weights:  64%|██████▍   | 136/211 [00:00<00:00, 14917.37it/s, Materializing param=encoder.layers.8.attention.q_proj.weight]
Loading weights:  64%|██████▍   | 136/211 [00:00<00:00, 14886.23it/s, Materializing param=encoder.layers.8.attention.q_proj.weight]
Loading weights:  65%|██████▍   | 137/211 [00:00<00:00, 14935.27it/s, Materializing param=encoder.layers.8.attention.v_proj.bias]  
Loading weights:  65%|██████▍   | 137/211 [00:00<00:00, 14902.73it/s, Materializing param=encoder.layers.8.attention.v_proj.bias]
Loading weights:  65%|██████▌   | 138/211 [00:00<00:00, 14951.41it/s, Materializing param=encoder.layers.8.attention.v_proj.weight]
Loading weights:  65%|██████▌   | 138/211 [00:00<00:00, 14917.50it/s, Materializing param=encoder.layers.8.attention.v_proj.weight]
Loading weights:  66%|██████▌   | 139/211 [00:00<00:00, 14967.35it/s, Materializing param=encoder.layers.8.feed_forward.intermediate_dense.bias]
Loading weights:  66%|██████▌   | 139/211 [00:00<00:00, 14933.61it/s, Materializing param=encoder.layers.8.feed_forward.intermediate_dense.bias]
Loading weights:  66%|██████▋   | 140/211 [00:00<00:00, 14976.60it/s, Materializing param=encoder.layers.8.feed_forward.intermediate_dense.weight]
Loading weights:  66%|██████▋   | 140/211 [00:00<00:00, 14946.49it/s, Materializing param=encoder.layers.8.feed_forward.intermediate_dense.weight]
Loading weights:  67%|██████▋   | 141/211 [00:00<00:00, 14992.19it/s, Materializing param=encoder.layers.8.feed_forward.output_dense.bias]        
Loading weights:  67%|██████▋   | 141/211 [00:00<00:00, 14958.82it/s, Materializing param=encoder.layers.8.feed_forward.output_dense.bias]
Loading weights:  67%|██████▋   | 142/211 [00:00<00:00, 15006.08it/s, Materializing param=encoder.layers.8.feed_forward.output_dense.weight]
Loading weights:  67%|██████▋   | 142/211 [00:00<00:00, 14972.88it/s, Materializing param=encoder.layers.8.feed_forward.output_dense.weight]
Loading weights:  68%|██████▊   | 143/211 [00:00<00:00, 15019.42it/s, Materializing param=encoder.layers.8.final_layer_norm.bias]           
Loading weights:  68%|██████▊   | 143/211 [00:00<00:00, 14988.27it/s, Materializing param=encoder.layers.8.final_layer_norm.bias]
Loading weights:  68%|██████▊   | 144/211 [00:00<00:00, 15035.97it/s, Materializing param=encoder.layers.8.final_layer_norm.weight]
Loading weights:  68%|██████▊   | 144/211 [00:00<00:00, 15003.10it/s, Materializing param=encoder.layers.8.final_layer_norm.weight]
Loading weights:  69%|██████▊   | 145/211 [00:00<00:00, 15052.70it/s, Materializing param=encoder.layers.8.layer_norm.bias]        
Loading weights:  69%|██████▊   | 145/211 [00:00<00:00, 15016.64it/s, Materializing param=encoder.layers.8.layer_norm.bias]
Loading weights:  69%|██████▉   | 146/211 [00:00<00:00, 15062.56it/s, Materializing param=encoder.layers.8.layer_norm.weight]
Loading weights:  69%|██████▉   | 146/211 [00:00<00:00, 15031.50it/s, Materializing param=encoder.layers.8.layer_norm.weight]
Loading weights:  70%|██████▉   | 147/211 [00:00<00:00, 15080.04it/s, Materializing param=encoder.layers.9.attention.k_proj.bias]
Loading weights:  70%|██████▉   | 147/211 [00:00<00:00, 15047.66it/s, Materializing param=encoder.layers.9.attention.k_proj.bias]
Loading weights:  70%|███████   | 148/211 [00:00<00:00, 15092.93it/s, Materializing param=encoder.layers.9.attention.k_proj.weight]
Loading weights:  70%|███████   | 148/211 [00:00<00:00, 15060.70it/s, Materializing param=encoder.layers.9.attention.k_proj.weight]
Loading weights:  71%|███████   | 149/211 [00:00<00:00, 15107.12it/s, Materializing param=encoder.layers.9.attention.out_proj.bias]
Loading weights:  71%|███████   | 149/211 [00:00<00:00, 15076.51it/s, Materializing param=encoder.layers.9.attention.out_proj.bias]
Loading weights:  71%|███████   | 150/211 [00:00<00:00, 15114.97it/s, Materializing param=encoder.layers.9.attention.out_proj.weight]
Loading weights:  71%|███████   | 150/211 [00:00<00:00, 15086.34it/s, Materializing param=encoder.layers.9.attention.out_proj.weight]
Loading weights:  72%|███████▏  | 151/211 [00:00<00:00, 15125.62it/s, Materializing param=encoder.layers.9.attention.q_proj.bias]    
Loading weights:  72%|███████▏  | 151/211 [00:00<00:00, 15095.34it/s, Materializing param=encoder.layers.9.attention.q_proj.bias]
Loading weights:  72%|███████▏  | 152/211 [00:00<00:00, 15139.73it/s, Materializing param=encoder.layers.9.attention.q_proj.weight]
Loading weights:  72%|███████▏  | 152/211 [00:00<00:00, 15109.59it/s, Materializing param=encoder.layers.9.attention.q_proj.weight]
Loading weights:  73%|███████▎  | 153/211 [00:00<00:00, 15154.76it/s, Materializing param=encoder.layers.9.attention.v_proj.bias]  
Loading weights:  73%|███████▎  | 153/211 [00:00<00:00, 15124.76it/s, Materializing param=encoder.layers.9.attention.v_proj.bias]
Loading weights:  73%|███████▎  | 154/211 [00:00<00:00, 15169.63it/s, Materializing param=encoder.layers.9.attention.v_proj.weight]
Loading weights:  73%|███████▎  | 154/211 [00:00<00:00, 15141.18it/s, Materializing param=encoder.layers.9.attention.v_proj.weight]
Loading weights:  73%|███████▎  | 155/211 [00:00<00:00, 15185.75it/s, Materializing param=encoder.layers.9.feed_forward.intermediate_dense.bias]
Loading weights:  73%|███████▎  | 155/211 [00:00<00:00, 15156.01it/s, Materializing param=encoder.layers.9.feed_forward.intermediate_dense.bias]
Loading weights:  74%|███████▍  | 156/211 [00:00<00:00, 15197.46it/s, Materializing param=encoder.layers.9.feed_forward.intermediate_dense.weight]
Loading weights:  74%|███████▍  | 156/211 [00:00<00:00, 15171.03it/s, Materializing param=encoder.layers.9.feed_forward.intermediate_dense.weight]
Loading weights:  74%|███████▍  | 157/211 [00:00<00:00, 15210.44it/s, Materializing param=encoder.layers.9.feed_forward.output_dense.bias]        
Loading weights:  74%|███████▍  | 157/211 [00:00<00:00, 15182.39it/s, Materializing param=encoder.layers.9.feed_forward.output_dense.bias]
Loading weights:  75%|███████▍  | 158/211 [00:00<00:00, 15223.28it/s, Materializing param=encoder.layers.9.feed_forward.output_dense.weight]
Loading weights:  75%|███████▍  | 158/211 [00:00<00:00, 15193.62it/s, Materializing param=encoder.layers.9.feed_forward.output_dense.weight]
Loading weights:  75%|███████▌  | 159/211 [00:00<00:00, 15232.85it/s, Materializing param=encoder.layers.9.final_layer_norm.bias]           
Loading weights:  75%|███████▌  | 159/211 [00:00<00:00, 15203.68it/s, Materializing param=encoder.layers.9.final_layer_norm.bias]
Loading weights:  76%|███████▌  | 160/211 [00:00<00:00, 15248.20it/s, Materializing param=encoder.layers.9.final_layer_norm.weight]
Loading weights:  76%|███████▌  | 160/211 [00:00<00:00, 15219.50it/s, Materializing param=encoder.layers.9.final_layer_norm.weight]
Loading weights:  76%|███████▋  | 161/211 [00:00<00:00, 15263.39it/s, Materializing param=encoder.layers.9.layer_norm.bias]        
Loading weights:  76%|███████▋  | 161/211 [00:00<00:00, 15233.09it/s, Materializing param=encoder.layers.9.layer_norm.bias]
Loading weights:  77%|███████▋  | 162/211 [00:00<00:00, 15274.64it/s, Materializing param=encoder.layers.9.layer_norm.weight]
Loading weights:  77%|███████▋  | 162/211 [00:00<00:00, 15245.85it/s, Materializing param=encoder.layers.9.layer_norm.weight]
Loading weights:  77%|███████▋  | 163/211 [00:00<00:00, 15288.17it/s, Materializing param=encoder.layers.10.attention.k_proj.bias]
Loading weights:  77%|███████▋  | 163/211 [00:00<00:00, 15259.50it/s, Materializing param=encoder.layers.10.attention.k_proj.bias]
Loading weights:  78%|███████▊  | 164/211 [00:00<00:00, 15295.77it/s, Materializing param=encoder.layers.10.attention.k_proj.weight]
Loading weights:  78%|███████▊  | 164/211 [00:00<00:00, 15269.96it/s, Materializing param=encoder.layers.10.attention.k_proj.weight]
Loading weights:  78%|███████▊  | 165/211 [00:00<00:00, 15290.77it/s, Materializing param=encoder.layers.10.attention.out_proj.bias]
Loading weights:  78%|███████▊  | 165/211 [00:00<00:00, 15265.13it/s, Materializing param=encoder.layers.10.attention.out_proj.bias]
Loading weights:  79%|███████▊  | 166/211 [00:00<00:00, 15303.64it/s, Materializing param=encoder.layers.10.attention.out_proj.weight]
Loading weights:  79%|███████▊  | 166/211 [00:00<00:00, 15277.11it/s, Materializing param=encoder.layers.10.attention.out_proj.weight]
Loading weights:  79%|███████▉  | 167/211 [00:00<00:00, 15310.02it/s, Materializing param=encoder.layers.10.attention.q_proj.bias]    
Loading weights:  79%|███████▉  | 167/211 [00:00<00:00, 15283.30it/s, Materializing param=encoder.layers.10.attention.q_proj.bias]
Loading weights:  80%|███████▉  | 168/211 [00:00<00:00, 15328.66it/s, Materializing param=encoder.layers.10.attention.q_proj.weight]
Loading weights:  80%|███████▉  | 168/211 [00:00<00:00, 15303.69it/s, Materializing param=encoder.layers.10.attention.q_proj.weight]
Loading weights:  80%|████████  | 169/211 [00:00<00:00, 15342.80it/s, Materializing param=encoder.layers.10.attention.v_proj.bias]  
Loading weights:  80%|████████  | 169/211 [00:00<00:00, 15313.63it/s, Materializing param=encoder.layers.10.attention.v_proj.bias]
Loading weights:  81%|████████  | 170/211 [00:00<00:00, 15352.83it/s, Materializing param=encoder.layers.10.attention.v_proj.weight]
Loading weights:  81%|████████  | 170/211 [00:00<00:00, 15324.79it/s, Materializing param=encoder.layers.10.attention.v_proj.weight]
Loading weights:  81%|████████  | 171/211 [00:00<00:00, 15361.12it/s, Materializing param=encoder.layers.10.feed_forward.intermediate_dense.bias]
Loading weights:  81%|████████  | 171/211 [00:00<00:00, 15332.22it/s, Materializing param=encoder.layers.10.feed_forward.intermediate_dense.bias]
Loading weights:  82%|████████▏ | 172/211 [00:00<00:00, 15369.64it/s, Materializing param=encoder.layers.10.feed_forward.intermediate_dense.weight]
Loading weights:  82%|████████▏ | 172/211 [00:00<00:00, 15340.88it/s, Materializing param=encoder.layers.10.feed_forward.intermediate_dense.weight]
Loading weights:  82%|████████▏ | 173/211 [00:00<00:00, 15375.14it/s, Materializing param=encoder.layers.10.feed_forward.output_dense.bias]        
Loading weights:  82%|████████▏ | 173/211 [00:00<00:00, 15344.91it/s, Materializing param=encoder.layers.10.feed_forward.output_dense.bias]
Loading weights:  82%|████████▏ | 174/211 [00:00<00:00, 15375.08it/s, Materializing param=encoder.layers.10.feed_forward.output_dense.weight]
Loading weights:  82%|████████▏ | 174/211 [00:00<00:00, 15347.92it/s, Materializing param=encoder.layers.10.feed_forward.output_dense.weight]
Loading weights:  83%|████████▎ | 175/211 [00:00<00:00, 15384.68it/s, Materializing param=encoder.layers.10.final_layer_norm.bias]           
Loading weights:  83%|████████▎ | 175/211 [00:00<00:00, 15360.54it/s, Materializing param=encoder.layers.10.final_layer_norm.bias]
Loading weights:  83%|████████▎ | 176/211 [00:00<00:00, 15399.65it/s, Materializing param=encoder.layers.10.final_layer_norm.weight]
Loading weights:  83%|████████▎ | 176/211 [00:00<00:00, 15375.59it/s, Materializing param=encoder.layers.10.final_layer_norm.weight]
Loading weights:  84%|████████▍ | 177/211 [00:00<00:00, 15414.15it/s, Materializing param=encoder.layers.10.layer_norm.bias]        
Loading weights:  84%|████████▍ | 177/211 [00:00<00:00, 15390.19it/s, Materializing param=encoder.layers.10.layer_norm.bias]
Loading weights:  84%|████████▍ | 178/211 [00:00<00:00, 15430.11it/s, Materializing param=encoder.layers.10.layer_norm.weight]
Loading weights:  84%|████████▍ | 178/211 [00:00<00:00, 15404.64it/s, Materializing param=encoder.layers.10.layer_norm.weight]
Loading weights:  85%|████████▍ | 179/211 [00:00<00:00, 15444.34it/s, Materializing param=encoder.layers.11.attention.k_proj.bias]
Loading weights:  85%|████████▍ | 179/211 [00:00<00:00, 15418.02it/s, Materializing param=encoder.layers.11.attention.k_proj.bias]
Loading weights:  85%|████████▌ | 180/211 [00:00<00:00, 15454.64it/s, Materializing param=encoder.layers.11.attention.k_proj.weight]
Loading weights:  85%|████████▌ | 180/211 [00:00<00:00, 15428.11it/s, Materializing param=encoder.layers.11.attention.k_proj.weight]
Loading weights:  86%|████████▌ | 181/211 [00:00<00:00, 15465.16it/s, Materializing param=encoder.layers.11.attention.out_proj.bias]
Loading weights:  86%|████████▌ | 181/211 [00:00<00:00, 15440.94it/s, Materializing param=encoder.layers.11.attention.out_proj.bias]
Loading weights:  86%|████████▋ | 182/211 [00:00<00:00, 15479.02it/s, Materializing param=encoder.layers.11.attention.out_proj.weight]
Loading weights:  86%|████████▋ | 182/211 [00:00<00:00, 15452.70it/s, Materializing param=encoder.layers.11.attention.out_proj.weight]
Loading weights:  87%|████████▋ | 183/211 [00:00<00:00, 15487.44it/s, Materializing param=encoder.layers.11.attention.q_proj.bias]    
Loading weights:  87%|████████▋ | 183/211 [00:00<00:00, 15462.79it/s, Materializing param=encoder.layers.11.attention.q_proj.bias]
Loading weights:  87%|████████▋ | 184/211 [00:00<00:00, 15497.65it/s, Materializing param=encoder.layers.11.attention.q_proj.weight]
Loading weights:  87%|████████▋ | 184/211 [00:00<00:00, 15471.24it/s, Materializing param=encoder.layers.11.attention.q_proj.weight]
Loading weights:  88%|████████▊ | 185/211 [00:00<00:00, 15505.90it/s, Materializing param=encoder.layers.11.attention.v_proj.bias]  
Loading weights:  88%|████████▊ | 185/211 [00:00<00:00, 15479.92it/s, Materializing param=encoder.layers.11.attention.v_proj.bias]
Loading weights:  88%|████████▊ | 186/211 [00:00<00:00, 15515.61it/s, Materializing param=encoder.layers.11.attention.v_proj.weight]
Loading weights:  88%|████████▊ | 186/211 [00:00<00:00, 15489.74it/s, Materializing param=encoder.layers.11.attention.v_proj.weight]
Loading weights:  89%|████████▊ | 187/211 [00:00<00:00, 15525.23it/s, Materializing param=encoder.layers.11.feed_forward.intermediate_dense.bias]
Loading weights:  89%|████████▊ | 187/211 [00:00<00:00, 15498.24it/s, Materializing param=encoder.layers.11.feed_forward.intermediate_dense.bias]
Loading weights:  89%|████████▉ | 188/211 [00:00<00:00, 15528.34it/s, Materializing param=encoder.layers.11.feed_forward.intermediate_dense.weight]
Loading weights:  89%|████████▉ | 188/211 [00:00<00:00, 15503.92it/s, Materializing param=encoder.layers.11.feed_forward.intermediate_dense.weight]
Loading weights:  90%|████████▉ | 189/211 [00:00<00:00, 15537.81it/s, Materializing param=encoder.layers.11.feed_forward.output_dense.bias]        
Loading weights:  90%|████████▉ | 189/211 [00:00<00:00, 15513.79it/s, Materializing param=encoder.layers.11.feed_forward.output_dense.bias]
Loading weights:  90%|█████████ | 190/211 [00:00<00:00, 15545.67it/s, Materializing param=encoder.layers.11.feed_forward.output_dense.weight]
Loading weights:  90%|█████████ | 190/211 [00:00<00:00, 15521.75it/s, Materializing param=encoder.layers.11.feed_forward.output_dense.weight]
Loading weights:  91%|█████████ | 191/211 [00:00<00:00, 15554.06it/s, Materializing param=encoder.layers.11.final_layer_norm.bias]           
Loading weights:  91%|█████████ | 191/211 [00:00<00:00, 15530.85it/s, Materializing param=encoder.layers.11.final_layer_norm.bias]
Loading weights:  91%|█████████ | 192/211 [00:00<00:00, 15566.89it/s, Materializing param=encoder.layers.11.final_layer_norm.weight]
Loading weights:  91%|█████████ | 192/211 [00:00<00:00, 15544.05it/s, Materializing param=encoder.layers.11.final_layer_norm.weight]
Loading weights:  91%|█████████▏| 193/211 [00:00<00:00, 15579.90it/s, Materializing param=encoder.layers.11.layer_norm.bias]        
Loading weights:  91%|█████████▏| 193/211 [00:00<00:00, 15554.76it/s, Materializing param=encoder.layers.11.layer_norm.bias]
Loading weights:  92%|█████████▏| 194/211 [00:00<00:00, 15591.31it/s, Materializing param=encoder.layers.11.layer_norm.weight]
Loading weights:  92%|█████████▏| 194/211 [00:00<00:00, 15570.13it/s, Materializing param=encoder.layers.11.layer_norm.weight]
Loading weights:  92%|█████████▏| 195/211 [00:00<00:00, 15605.00it/s, Materializing param=encoder.pos_conv_embed.conv.bias]   
Loading weights:  92%|█████████▏| 195/211 [00:00<00:00, 15581.51it/s, Materializing param=encoder.pos_conv_embed.conv.bias]
Loading weights:  93%|█████████▎| 196/211 [00:00<00:00, 15609.08it/s, Materializing param=encoder.pos_conv_embed.conv.parametrizations.weight.original0]
Loading weights:  93%|█████████▎| 196/211 [00:00<00:00, 15585.41it/s, Materializing param=encoder.pos_conv_embed.conv.parametrizations.weight.original0]
Loading weights:  93%|█████████▎| 197/211 [00:00<00:00, 15605.46it/s, Materializing param=encoder.pos_conv_embed.conv.parametrizations.weight.original1]
Loading weights:  93%|█████████▎| 197/211 [00:00<00:00, 15580.74it/s, Materializing param=encoder.pos_conv_embed.conv.parametrizations.weight.original1]
Loading weights:  94%|█████████▍| 198/211 [00:00<00:00, 15595.72it/s, Materializing param=feature_extractor.conv_layers.0.conv.weight]                  
Loading weights:  94%|█████████▍| 198/211 [00:00<00:00, 15573.49it/s, Materializing param=feature_extractor.conv_layers.0.conv.weight]
Loading weights:  94%|█████████▍| 199/211 [00:00<00:00, 15597.16it/s, Materializing param=feature_extractor.conv_layers.0.layer_norm.bias]
Loading weights:  94%|█████████▍| 199/211 [00:00<00:00, 15573.59it/s, Materializing param=feature_extractor.conv_layers.0.layer_norm.bias]
Loading weights:  95%|█████████▍| 200/211 [00:00<00:00, 15605.55it/s, Materializing param=feature_extractor.conv_layers.0.layer_norm.weight]
Loading weights:  95%|█████████▍| 200/211 [00:00<00:00, 15582.65it/s, Materializing param=feature_extractor.conv_layers.0.layer_norm.weight]
Loading weights:  95%|█████████▌| 201/211 [00:00<00:00, 15616.47it/s, Materializing param=feature_extractor.conv_layers.1.conv.weight]      
Loading weights:  95%|█████████▌| 201/211 [00:00<00:00, 15595.96it/s, Materializing param=feature_extractor.conv_layers.1.conv.weight]
Loading weights:  96%|█████████▌| 202/211 [00:00<00:00, 15628.74it/s, Materializing param=feature_extractor.conv_layers.2.conv.weight]
Loading weights:  96%|█████████▌| 202/211 [00:00<00:00, 15607.14it/s, Materializing param=feature_extractor.conv_layers.2.conv.weight]
Loading weights:  96%|█████████▌| 203/211 [00:00<00:00, 15639.46it/s, Materializing param=feature_extractor.conv_layers.3.conv.weight]
Loading weights:  96%|█████████▌| 203/211 [00:00<00:00, 15615.37it/s, Materializing param=feature_extractor.conv_layers.3.conv.weight]
Loading weights:  97%|█████████▋| 204/211 [00:00<00:00, 15649.24it/s, Materializing param=feature_extractor.conv_layers.4.conv.weight]
Loading weights:  97%|█████████▋| 204/211 [00:00<00:00, 15624.95it/s, Materializing param=feature_extractor.conv_layers.4.conv.weight]
Loading weights:  97%|█████████▋| 205/211 [00:00<00:00, 15656.09it/s, Materializing param=feature_extractor.conv_layers.5.conv.weight]
Loading weights:  97%|█████████▋| 205/211 [00:00<00:00, 15634.74it/s, Materializing param=feature_extractor.conv_layers.5.conv.weight]
Loading weights:  98%|█████████▊| 206/211 [00:00<00:00, 15650.10it/s, Materializing param=feature_extractor.conv_layers.6.conv.weight]
Loading weights:  98%|█████████▊| 206/211 [00:00<00:00, 15628.59it/s, Materializing param=feature_extractor.conv_layers.6.conv.weight]
Loading weights:  98%|█████████▊| 207/211 [00:00<00:00, 15659.42it/s, Materializing param=feature_projection.layer_norm.bias]         
Loading weights:  98%|█████████▊| 207/211 [00:00<00:00, 15637.99it/s, Materializing param=feature_projection.layer_norm.bias]
Loading weights:  99%|█████████▊| 208/211 [00:00<00:00, 15673.44it/s, Materializing param=feature_projection.layer_norm.weight]
Loading weights:  99%|█████████▊| 208/211 [00:00<00:00, 15652.07it/s, Materializing param=feature_projection.layer_norm.weight]
Loading weights:  99%|█████████▉| 209/211 [00:00<00:00, 15686.23it/s, Materializing param=feature_projection.projection.bias]  
Loading weights:  99%|█████████▉| 209/211 [00:00<00:00, 15664.93it/s, Materializing param=feature_projection.projection.bias]
Loading weights: 100%|█████████▉| 210/211 [00:00<00:00, 15702.00it/s, Materializing param=feature_projection.projection.weight]
Loading weights: 100%|█████████▉| 210/211 [00:00<00:00, 15677.41it/s, Materializing param=feature_projection.projection.weight]
Loading weights: 100%|██████████| 211/211 [00:00<00:00, 15714.58it/s, Materializing param=masked_spec_embed]                   
Loading weights: 100%|██████████| 211/211 [00:00<00:00, 15690.07it/s, Materializing param=masked_spec_embed]
Loading weights: 100%|██████████| 211/211 [00:00<00:00, 15624.14it/s, Materializing param=masked_spec_embed]
[2026-02-01 14:56:11,107][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/microsoft/wavlm-base-plus "HTTP/1.1 200 OK"
Wav2Vec2Model LOAD REPORT from: microsoft/wavlm-base-plus
Key                                                         | Status     |  | 
------------------------------------------------------------+------------+--+-
encoder.layers.{0...11}.attention.gru_rel_pos_const         | UNEXPECTED |  | 
encoder.layers.{0...11}.attention.gru_rel_pos_linear.weight | UNEXPECTED |  | 
encoder.layers.{0...11}.attention.gru_rel_pos_linear.bias   | UNEXPECTED |  | 
encoder.layers.0.attention.rel_attn_embed.weight            | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (mps), used: True
TPU available: False, using: 0 TPU cores
💡 Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.
IA3 applied: 94,402,472 -> 36,864 trainable params
Trainable params reduced to 0.04%
[2026-02-01 14:56:11,198][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/microsoft/wavlm-base-plus/commits/main "HTTP/1.1 200 OK"
[2026-02-01 14:56:11,366][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/microsoft/wavlm-base-plus/discussions?p=0 "HTTP/1.1 200 OK"
[2026-02-01 14:56:11,453][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/microsoft/wavlm-base-plus/commits/refs%2Fpr%2F2 "HTTP/1.1 200 OK"
[2026-02-01 14:56:11,535][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/microsoft/wavlm-base-plus/resolve/refs%2Fpr%2F2/model.safetensors.index.json "HTTP/1.1 404 Not Found"
wandb: WARNING The anonymous setting has no effect and will be removed in a future version.
[2026-02-01 14:56:11,612][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/microsoft/wavlm-base-plus/resolve/refs%2Fpr%2F2/model.safetensors "HTTP/1.1 302 Found"
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id etg1upvu.
wandb: Tracking run with wandb version 0.24.1
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in wandb/offline-run-20260201_145611-etg1upvu
/Users/zakkeown/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name              | Type                          | Params | Mode  | FLOPs
------------------------------------------------------------------------------------
0 | model             | PeftModelForFeatureExtraction | 94.4 M | train | 0    
1 | train_acc         | MulticlassAccuracy            | 0      | train | 0    
2 | val_acc           | MulticlassAccuracy            | 0      | train | 0    
3 | test_acc          | MulticlassAccuracy            | 0      | train | 0    
4 | val_f1            | MulticlassF1Score             | 0      | train | 0    
5 | val_f1_per_class  | MulticlassF1Score             | 0      | train | 0    
6 | val_confusion     | MulticlassConfusionMatrix     | 0      | train | 0    
7 | test_f1           | MulticlassF1Score             | 0      | train | 0    
8 | test_f1_per_class | MulticlassF1Score             | 0      | train | 0    
9 | test_confusion    | MulticlassConfusionMatrix     | 0      | train | 0    
------------------------------------------------------------------------------------
36.9 K    Trainable params
94.4 M    Non-trainable params
94.4 M    Total params
377.757   Total estimated model params size (MB)
109       Modules in train mode
220       Modules in eval mode
0         Total Flops

Sanity Checking: |          | 0/? [00:00<?, ?it/s]/Users/zakkeown/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pytorch_lightning/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
/Users/zakkeown/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:429: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.

Sanity Checking: |          | 0/? [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s]
                                                                           /Users/zakkeown/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pytorch_lightning/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
/Users/zakkeown/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:429: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.

/Users/zakkeown/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
/Users/zakkeown/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:534: Found 220 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.

Training: |          | 0/? [00:00<?, ?it/s]
Training: |          | 0/? [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s]
Epoch 0:  33%|███▎      | 1/3 [00:03<00:06,  0.31it/s]
Epoch 0:  33%|███▎      | 1/3 [00:03<00:06,  0.31it/s, v_num=upvu, train/loss=3.810]
Epoch 0:  67%|██████▋   | 2/3 [00:03<00:01,  0.56it/s, v_num=upvu, train/loss=3.810]
Epoch 0:  67%|██████▋   | 2/3 [00:03<00:01,  0.56it/s, v_num=upvu, train/loss=3.810]
Epoch 0: 100%|██████████| 3/3 [00:03<00:00,  0.79it/s, v_num=upvu, train/loss=3.810]
Epoch 0: 100%|██████████| 3/3 [00:03<00:00,  0.79it/s, v_num=upvu, train/loss=3.820]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s][A

                                                                      [A
Epoch 0: 100%|██████████| 3/3 [00:09<00:00,  0.32it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]
Epoch 0: 100%|██████████| 3/3 [00:09<00:00,  0.32it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]
Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]        
Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]
Epoch 1:  33%|███▎      | 1/3 [00:15<00:30,  0.06it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]
Epoch 1:  33%|███▎      | 1/3 [00:15<00:30,  0.06it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]
Epoch 1:  67%|██████▋   | 2/3 [00:15<00:07,  0.13it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]
Epoch 1:  67%|██████▋   | 2/3 [00:15<00:07,  0.13it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 1: 100%|██████████| 3/3 [00:15<00:00,  0.19it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 1: 100%|██████████| 3/3 [00:15<00:00,  0.19it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s][A

                                                                      [A
Epoch 1: 100%|██████████| 3/3 [00:21<00:00,  0.14it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 1: 100%|██████████| 3/3 [00:21<00:00,  0.14it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]        
Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 2:  33%|███▎      | 1/3 [00:15<00:30,  0.06it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 2:  33%|███▎      | 1/3 [00:15<00:30,  0.06it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 2:  67%|██████▋   | 2/3 [00:15<00:07,  0.13it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 2:  67%|██████▋   | 2/3 [00:15<00:07,  0.13it/s, v_num=upvu, train/loss=3.810, val/loss=3.810]
Epoch 2: 100%|██████████| 3/3 [00:15<00:00,  0.19it/s, v_num=upvu, train/loss=3.810, val/loss=3.810]
Epoch 2: 100%|██████████| 3/3 [00:15<00:00,  0.19it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s][A

                                                                      [A
Epoch 2: 100%|██████████| 3/3 [00:21<00:00,  0.14it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]
Epoch 2: 100%|██████████| 3/3 [00:21<00:00,  0.14it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]
Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]        
Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]
Epoch 3:  33%|███▎      | 1/3 [00:15<00:30,  0.06it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]
Epoch 3:  33%|███▎      | 1/3 [00:15<00:30,  0.06it/s, v_num=upvu, train/loss=3.810, val/loss=3.810]
Epoch 3:  67%|██████▋   | 2/3 [00:15<00:07,  0.13it/s, v_num=upvu, train/loss=3.810, val/loss=3.810]
Epoch 3:  67%|██████▋   | 2/3 [00:15<00:07,  0.13it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 3: 100%|██████████| 3/3 [00:15<00:00,  0.19it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 3: 100%|██████████| 3/3 [00:15<00:00,  0.19it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s][A

                                                                      [A
Epoch 3: 100%|██████████| 3/3 [00:21<00:00,  0.14it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 3: 100%|██████████| 3/3 [00:21<00:00,  0.14it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]        
Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 4:  33%|███▎      | 1/3 [00:15<00:30,  0.06it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 4:  33%|███▎      | 1/3 [00:15<00:30,  0.06it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 4:  67%|██████▋   | 2/3 [00:15<00:07,  0.13it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 4:  67%|██████▋   | 2/3 [00:15<00:07,  0.13it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 4: 100%|██████████| 3/3 [00:15<00:00,  0.19it/s, v_num=upvu, train/loss=3.800, val/loss=3.810]
Epoch 4: 100%|██████████| 3/3 [00:15<00:00,  0.19it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation: |          | 0/? [00:00<?, ?it/s][A

Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A

Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s][A

                                                                      [A
Epoch 4: 100%|██████████| 3/3 [00:21<00:00,  0.14it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]
Epoch 4: 100%|██████████| 3/3 [00:21<00:00,  0.14it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]`Trainer.fit` stopped: `max_epochs=5` reached.

Epoch 4: 100%|██████████| 3/3 [00:21<00:00,  0.14it/s, v_num=upvu, train/loss=3.820, val/loss=3.810]/Users/zakkeown/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pytorch_lightning/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
/Users/zakkeown/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:429: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.


Testing: |          | 0/? [00:00<?, ?it/s]
Testing: |          | 0/? [00:00<?, ?it/s]
Testing DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]
Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]
Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
             Test metric                         DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
              test/acc                                0.0
    test/f1_best/ten-stroke-roll                      0.0
  test/f1_best/thirteen-stroke-roll                   0.0
   test/f1_best/triple-paradiddle                     0.0
    test/f1_best/triple-ratamacue                     0.0
   test/f1_best/triple-stroke-roll                    0.0
            test/f1_macro                             0.0
    test/f1_worst/double-drag-tap                     0.0
   test/f1_worst/double-paradiddle                    0.0
   test/f1_worst/double-ratamacue                     0.0
test/f1_worst/double-stroke-open-roll                 0.0
         test/f1_worst/drag                           0.0
              test/loss                       3.8462891578674316
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync wandb/offline-run-20260201_145611-etg1upvu[0m
